{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"data/winemag-data-130k-v2.csv\")\n",
    "raw_descriptions = raw_data['description']\n",
    "raw_varieties = raw_data['variety']\n",
    "raw_provinces = raw_data['province']\n",
    "raw_points = raw_data['points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_varieties = set(['pinot noir', 'chardonnay', 'cabernet sauvignon', 'red blend', 'bordeaux-style red blend', 'riesling', 'sauvignon blanc', 'syrah', 'rosé', 'merlot', 'nebbiolo', 'zinfandel', 'sangiovese', 'malbec', 'portuguese red', 'white blend', 'sparkling blend', 'tempranillo', 'rhône-style red blend', 'pinot gris', 'champagne blend', 'cabernet franc', 'grüner veltliner', 'portuguese white', 'bordeaux-style white blend', 'pinot grigio', 'gamay', 'gewürztraminer', 'viognier', 'shiraz'])\n",
    "excluded_words = set(['pinot', 'noir', 'chardonnay', 'cabernet', 'sauvignon', 'bordeaux-style', 'blend', 'riesling', 'sauvignon',  'blanc', 'syrah', 'rosé', 'merlot', 'nebbiolo', 'zinfandel', 'sangiovese', 'malbec', 'portuguese', 'tempranillo', 'rhône-style', 'pinot', 'gris', 'champagne', 'franc', 'grüner',  'veltliner', 'portuguese', 'grigio', 'gamay', 'gewürztraminer', 'viognier', 'shiraz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105154 105154\n"
     ]
    }
   ],
   "source": [
    "# Extract rows with just the valid varieties\n",
    "\n",
    "def process_description(des):\n",
    "    processed_description = []\n",
    "    \n",
    "    table = str.maketrans({key: None for key in string.punctuation})\n",
    "    des = des.translate(table)\n",
    "    \n",
    "    for word in des.split():\n",
    "        word = word.lower()\n",
    "        if word not in excluded_words:\n",
    "            processed_description.append(word)\n",
    "            \n",
    "    return \" \".join(processed_description)\n",
    "\n",
    "data, labels = [], []\n",
    "for i, variety in enumerate(raw_varieties):\n",
    "    if type(variety) is not float:\n",
    "        variety = variety.lower()\n",
    "        if variety.lower() in valid_varieties:\n",
    "            if type(raw_descriptions[i]) is not float:                \n",
    "                data.append(process_description(raw_descriptions[i]))\n",
    "                labels.append(variety)\n",
    "\n",
    "print(len(data), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aromas include tropical fruit broom brimstone and dried herb the palate isnt overly expressive offering unripened apple citrus and dried sage alongside brisk acidity', 'this is ripe and fruity a wine that is smooth while still structured firm tannins are filled out with juicy red berry fruits and freshened with acidity its already drinkable although it will certainly be better from 2016', 'tart and snappy the flavors of lime flesh and rind dominate some green pineapple pokes through with crisp acidity underscoring the flavors the wine was all stainlesssteel fermented', 'pineapple rind lemon pith and orange blossom start off the aromas the palate is a bit more opulent with notes of honeydrizzled guava and mango giving way to a slightly astringent semidry finish', 'much like the regular bottling from 2012 this comes across as rather rough and tannic with rustic earthy herbal characteristics nonetheless if you think of it as a pleasantly unfussy country wine its a good companion to a hearty winter stew']\n"
     ]
    }
   ],
   "source": [
    "# Print a sample of the data\n",
    "\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84123,) (84123,)\n",
      "(21031,) (21031,)\n"
     ]
    }
   ],
   "source": [
    "# Split 80/20 training-test\n",
    "\n",
    "stacked = np.hstack([np.array(data).reshape(-1, 1), np.array(labels).reshape(-1, 1)])\n",
    "np.random.shuffle(stacked)\n",
    "\n",
    "train_split = int(len(stacked) * 0.8)\n",
    "\n",
    "train_data = stacked[:train_split, :1].reshape(-1,)\n",
    "train_labels = stacked[:train_split, 1:].reshape(-1,)\n",
    "\n",
    "test_data = stacked[train_split:, :1].reshape(-1,)\n",
    "test_labels = stacked[train_split:, 1:].reshape(-1,)\n",
    "\n",
    "print(train_data.shape, train_labels.shape)\n",
    "print(test_data.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33486\n",
      "613277\n"
     ]
    }
   ],
   "source": [
    "# Compile vocabulary\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "tf_idf_vectorizer = TfidfVectorizer(stop_words='english', token_pattern='[a-z]+', ngram_range=(1, 1))\n",
    "\n",
    "# tokenize and build vocab\n",
    "tf_idf_vectorizer.fit(train_data)\n",
    "\n",
    "# summarize\n",
    "print(len(tf_idf_vectorizer.vocabulary_))\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words='english', token_pattern='[a-z]+', ngram_range=(1, 2))\n",
    "count_vectorizer.fit(train_data)\n",
    "\n",
    "print(len(count_vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def multinomial_nb(vectorizer, train_data, train_labels, test_data, test_labels):\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(vectorizer.transform(train_data), train_labels)\n",
    "    return clf.score(vectorizer.transform(test_data), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy Classifier\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "def dummy_classifier(vectorizer, train_data, train_labels, test_data, test_labels):\n",
    "    dummy_clf = DummyClassifier()\n",
    "    dummy_clf.fit(vectorizer.transform(train_data), train_labels)\n",
    "    return dummy_clf.score(vectorizer.transform(test_data), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def logistic_regression(vectorizer, train_data, train_labels, test_data, test_labels):\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(vectorizer.transform(train_data), train_labels)\n",
    "    return lr.score(vectorizer.transform(test_data), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6545100090342827"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression(count_vectorizer, train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments():\n",
    "    # Bag of words\n",
    "    count_vectorizer = CountVectorizer(stop_words='english', token_pattern='[a-z]+', ngram_range=(1, 1))\n",
    "    count_vectorizer.fit(train_data)\n",
    "\n",
    "    print(multinomial_nb(count_vectorizer, train_data, train_labels, test_data, test_labels))\n",
    "    print(logistic_regression(count_vectorizer, train_data, train_labels, test_data, test_labels))\n",
    "\n",
    "    # Bigrams\n",
    "    count_vectorizer = CountVectorizer(stop_words='english', token_pattern='[a-z]+', ngram_range=(1, 2))\n",
    "    count_vectorizer.fit(train_data)\n",
    "\n",
    "    print(multinomial_nb(count_vectorizer, train_data, train_labels, test_data, test_labels))\n",
    "    print(logistic_regression(count_vectorizer, train_data, train_labels, test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5386334458656269\n",
      "0.6295944082544814\n",
      "0.4781513004612239\n",
      "0.6545100090342827\n"
     ]
    }
   ],
   "source": [
    "run_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
