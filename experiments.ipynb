{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/nyc/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"data/winemag-data-130k-v2.csv\")\n",
    "raw_descriptions = raw_data['description']\n",
    "raw_varieties = raw_data['variety']\n",
    "raw_provinces = raw_data['province']\n",
    "raw_points = raw_data['points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_varieties = set(['pinot noir', 'chardonnay', 'cabernet sauvignon', 'red blend', 'bordeaux-style red blend', 'riesling', 'sauvignon blanc', 'syrah', 'rosé', 'merlot', 'nebbiolo', 'zinfandel', 'sangiovese', 'malbec', 'portuguese red', 'white blend', 'sparkling blend', 'tempranillo', 'rhône-style red blend', 'pinot gris', 'champagne blend', 'cabernet franc', 'grüner veltliner', 'portuguese white', 'bordeaux-style white blend', 'pinot grigio', 'gamay', 'gewürztraminer', 'viognier', 'shiraz'])\n",
    "excluded_words = set(['pinot', 'noir', 'chardonnay', 'cabernet', 'sauvignon', 'bordeaux-style', 'blend', 'riesling', 'sauvignon',  'blanc', 'syrah', 'rosé', 'merlot', 'nebbiolo', 'zinfandel', 'sangiovese', 'malbec', 'portuguese', 'tempranillo', 'rhône-style', 'pinot', 'gris', 'champagne', 'franc', 'grüner',  'veltliner', 'portuguese', 'grigio', 'gamay', 'gewürztraminer', 'viognier', 'shiraz', 'flavor', 'wine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105154 105154\n"
     ]
    }
   ],
   "source": [
    "# Extract rows with just the valid varieties\n",
    "\n",
    "def process_description(des):\n",
    "    stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "    processed_description = []\n",
    "    \n",
    "    table = str.maketrans({key: None for key in string.punctuation})\n",
    "    des = des.translate(table)\n",
    "    \n",
    "    for word in des.split():\n",
    "        word = word.lower()\n",
    "        word = stemmer.stem(word)\n",
    "        if word not in excluded_words:\n",
    "            processed_description.append(word)\n",
    "            \n",
    "    return \" \".join(processed_description)\n",
    "\n",
    "data, labels = [], []\n",
    "for i, variety in enumerate(raw_varieties):\n",
    "    if type(variety) is not float:\n",
    "        variety = variety.lower()\n",
    "        if variety.lower() in valid_varieties:\n",
    "            if type(raw_descriptions[i]) is not float:                \n",
    "                data.append(process_description(raw_descriptions[i]))\n",
    "                labels.append(variety)\n",
    "\n",
    "print(len(data), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aroma includ tropic fruit broom brimston and dri herb the palat isnt over express offer unripen appl citrus and dri sage alongsid brisk acid', 'this is ripe and fruiti a that is smooth while still structur firm tannin are fill out with juici red berri fruit and freshen with acid its alreadi drinkabl although it will certain be better from 2016', 'tart and snappi the of lime flesh and rind domin some green pineappl poke through with crisp acid underscor the the was all stainlesssteel ferment', 'pineappl rind lemon pith and orang blossom start off the aroma the palat is a bit more opul with note of honeydrizzl guava and mango give way to a slight astring semidri finish', 'much like the regular bottl from 2012 this come across as rather rough and tannic with rustic earthi herbal characterist nonetheless if you think of it as a pleasant unfussi countri its a good companion to a hearti winter stew']\n"
     ]
    }
   ],
   "source": [
    "# Print a sample of the data\n",
    "\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84123,) (84123,)\n",
      "(21031,) (21031,)\n"
     ]
    }
   ],
   "source": [
    "# Split 80/20 training-test\n",
    "\n",
    "stacked = np.hstack([np.array(data).reshape(-1, 1), np.array(labels).reshape(-1, 1)])\n",
    "np.random.shuffle(stacked)\n",
    "\n",
    "train_split = int(len(stacked) * 0.8)\n",
    "\n",
    "train_data = stacked[:train_split, :1].reshape(-1,)\n",
    "train_labels = stacked[:train_split, 1:].reshape(-1,)\n",
    "\n",
    "test_data = stacked[train_split:, :1].reshape(-1,)\n",
    "test_labels = stacked[train_split:, 1:].reshape(-1,)\n",
    "\n",
    "print(train_data.shape, train_labels.shape)\n",
    "print(test_data.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25665\n",
      "513635\n"
     ]
    }
   ],
   "source": [
    "# Compile vocabulary\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "tf_idf_vectorizer = TfidfVectorizer(stop_words='english', token_pattern='[a-z]+', ngram_range=(1, 1))\n",
    "\n",
    "# tokenize and build vocab\n",
    "tf_idf_vectorizer.fit(train_data)\n",
    "\n",
    "# summarize\n",
    "print(len(tf_idf_vectorizer.vocabulary_))\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words='english', token_pattern='[a-z]+', ngram_range=(1, 2))\n",
    "count_vectorizer.fit(train_data)\n",
    "\n",
    "print(len(count_vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def multinomial_nb(vectorizer, train_data, train_labels, test_data, test_labels):\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(vectorizer.transform(train_data), train_labels)\n",
    "    return clf.score(vectorizer.transform(test_data), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy Classifier\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "def dummy_classifier(vectorizer, train_data, train_labels, test_data, test_labels):\n",
    "    dummy_clf = DummyClassifier()\n",
    "    dummy_clf.fit(vectorizer.transform(train_data), train_labels)\n",
    "    return dummy_clf.score(vectorizer.transform(test_data), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def logistic_regression(vectorizer, train_data, train_labels, test_data, test_labels):\n",
    "    lr = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "    lr.fit(vectorizer.transform(train_data), train_labels)\n",
    "    return lr.score(vectorizer.transform(test_data), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments():\n",
    "    # Bag of words\n",
    "    count_vectorizer = CountVectorizer(stop_words='english', token_pattern='[a-z]+', ngram_range=(1, 1))\n",
    "    count_vectorizer.fit(train_data)\n",
    "\n",
    "    print(multinomial_nb(count_vectorizer, train_data, train_labels, test_data, test_labels))\n",
    "    print(logistic_regression(count_vectorizer, train_data, train_labels, test_data, test_labels))\n",
    "\n",
    "    # Bigrams\n",
    "    count_vectorizer = CountVectorizer(stop_words='english', token_pattern='[a-z]+', ngram_range=(1, 2))\n",
    "    count_vectorizer.fit(train_data)\n",
    "\n",
    "    print(multinomial_nb(count_vectorizer, train_data, train_labels, test_data, test_labels))\n",
    "    print(logistic_regression(count_vectorizer, train_data, train_labels, test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5490941942846275\n",
      "0.6258380485949313\n",
      "0.48666254576577433\n",
      "0.6517046265037326\n"
     ]
    }
   ],
   "source": [
    "run_experiments()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
