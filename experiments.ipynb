{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/paperspace/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"data/winemag-data-130k-v2.csv\")\n",
    "raw_descriptions = raw_data['description']\n",
    "raw_varieties = raw_data['variety']\n",
    "raw_provinces = raw_data['province']\n",
    "raw_points = raw_data['points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119955"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(raw_descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pinot noir': 0, 'chardonnay': 1, 'cabernet sauvignon': 2, 'riesling': 3, 'sauvignon blanc': 4, 'syrah': 5, 'rosé': 6, 'merlot': 7, 'nebbiolo': 8, 'zinfandel': 9, 'sangiovese': 10, 'malbec': 11}\n"
     ]
    }
   ],
   "source": [
    "valid_varieties = set(['pinot noir', 'chardonnay', 'cabernet sauvignon', 'riesling', 'sauvignon blanc', 'syrah', 'rosé', 'merlot', 'nebbiolo', 'zinfandel', 'sangiovese', 'malbec']) #, 'portuguese red', 'white blend', 'sparkling blend', 'tempranillo', 'rhône-style red blend', 'pinot gris', 'champagne blend', 'cabernet franc', 'grüner veltliner', 'portuguese white', 'bordeaux-style white blend', 'pinot grigio', 'gamay', 'gewürztraminer', 'viognier', 'shiraz'])\n",
    "excluded_words = set(['pinot', 'noir', 'chardonnay', 'cabernet', 'sauvignon', 'bordeaux-style', 'blend', 'riesling', 'sauvignon',  'blanc', 'syrah', 'rosé', 'merlot', 'nebbiolo', 'zinfandel', 'sangiovese', 'malbec', 'portuguese', 'tempranillo', 'rhône-style', 'pinot', 'gris', 'champagne', 'franc', 'grüner',  'veltliner', 'portuguese', 'grigio', 'gamay', 'gewürztraminer', 'viognier', 'shiraz', 'flavor', 'wine'])\n",
    "\n",
    "varieties = ['pinot noir', 'chardonnay', 'cabernet sauvignon', 'riesling', 'sauvignon blanc', 'syrah', 'rosé', 'merlot', 'nebbiolo', 'zinfandel', 'sangiovese', 'malbec']\n",
    "label_to_idx = {word: idx for idx, word in enumerate(varieties)}\n",
    "print(label_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66338 66338\n"
     ]
    }
   ],
   "source": [
    "# Extract rows with just the valid varieties\n",
    "\n",
    "def process_description(des):\n",
    "    stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "    processed_description = []\n",
    "    \n",
    "    table = str.maketrans({key: None for key in string.punctuation})\n",
    "    des = des.translate(table)\n",
    "    \n",
    "    for word in des.split():\n",
    "        word = word.lower()\n",
    "        word = stemmer.stem(word)\n",
    "        if word not in excluded_words:\n",
    "            processed_description.append(word)\n",
    "            \n",
    "    return \" \".join(processed_description)\n",
    "\n",
    "data, labels = [], []\n",
    "for i, variety in enumerate(raw_varieties):\n",
    "    if type(variety) is not float:\n",
    "        variety = variety.lower()\n",
    "        if variety.lower() in valid_varieties:\n",
    "            if type(raw_descriptions[i]) is not float:                \n",
    "                data.append(process_description(raw_descriptions[i]))\n",
    "                labels.append(variety)\n",
    "\n",
    "print(len(data), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pineappl rind lemon pith and orang blossom start off the aroma the palat is a bit more opul with note of honeydrizzl guava and mango give way to a slight astring semidri finish', 'much like the regular bottl from 2012 this come across as rather rough and tannic with rustic earthi herbal characterist nonetheless if you think of it as a pleasant unfussi countri its a good companion to a hearti winter stew', 'soft suppl plum envelop an oaki structur in this support by 15 coffe and chocol complet the pictur finish strong at the end result in a valuepr of attract and immedi access', 'slight reduc this offer a chalki tannic backbon to an otherwis juici explos of rich black cherri the whole accent throughout by firm oak and cigar box', 'build on 150 year and six generat of winemak tradit the wineri trend toward a leaner style with the classic california buttercream aroma cut by tart green appl in this good everyday sip that rang from pear to bare ripe pineappl prove approach but not distinct']\n"
     ]
    }
   ],
   "source": [
    "# Print a sample of the data\n",
    "\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53070,) (53070,)\n",
      "(13268,) (13268,)\n"
     ]
    }
   ],
   "source": [
    "# Split 80/20 training-test\n",
    "\n",
    "stacked = np.hstack([np.array(data).reshape(-1, 1), np.array(labels).reshape(-1, 1)])\n",
    "np.random.shuffle(stacked)\n",
    "\n",
    "train_split = int(len(stacked) * 0.8)\n",
    "\n",
    "train_data = stacked[:train_split, :1].reshape(-1,)\n",
    "train_labels = stacked[:train_split, 1:].reshape(-1,)\n",
    "\n",
    "test_data = stacked[train_split:, :1].reshape(-1,)\n",
    "test_labels = stacked[train_split:, 1:].reshape(-1,)\n",
    "\n",
    "print(train_data.shape, train_labels.shape)\n",
    "print(test_data.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(data, labels):\n",
    "    return SMOTE().fit_sample(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19792\n",
      "380249\n"
     ]
    }
   ],
   "source": [
    "# Compile vocabulary\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "tf_idf_vectorizer = TfidfVectorizer(stop_words='english', token_pattern='[a-z]+', ngram_range=(1, 1))\n",
    "\n",
    "# tokenize and build vocab\n",
    "tf_idf_vectorizer.fit(train_data)\n",
    "\n",
    "# summarize\n",
    "print(len(tf_idf_vectorizer.vocabulary_))\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words='english', token_pattern='[a-z]+', ngram_range=(1, 2))\n",
    "count_vectorizer.fit(train_data)\n",
    "\n",
    "print(len(count_vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def multinomial_nb(vectorizer, train_data, train_labels, test_data, test_labels):\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(vectorizer.transform(train_data), train_labels)\n",
    "    return clf.score(vectorizer.transform(test_data), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy Classifier\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "def dummy_classifier(vectorizer, train_data, train_labels, test_data, test_labels):\n",
    "    dummy_clf = DummyClassifier()\n",
    "    dummy_clf.fit(vectorizer.transform(train_data), train_labels)\n",
    "    return dummy_clf.score(vectorizer.transform(test_data), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def logistic_regression(vectorizer, train_data, train_labels, test_data, test_labels):\n",
    "    lr = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "    lr.fit(vectorizer.transform(train_data), train_labels)\n",
    "    return lr.score(vectorizer.transform(test_data), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def svc(vectorizer, train_data, train_labels, test_data, test_labels):\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(vectorizer.transform(train_data), train_labels)\n",
    "    return clf.score(vectorizer.transform(test_data), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments():\n",
    "    # Bag of words\n",
    "    count_vectorizer = CountVectorizer(stop_words='english', token_pattern='[a-z]+', ngram_range=(1, 1))\n",
    "    count_vectorizer.fit(train_data)\n",
    "\n",
    "    print(multinomial_nb(count_vectorizer, train_data, train_labels, test_data, test_labels))\n",
    "    print(logistic_regression(count_vectorizer, train_data, train_labels, test_data, test_labels))\n",
    "    print(svc(count_vectorizer, train_data, train_labels, test_data, test_labels))\n",
    "\n",
    "    # Bigrams\n",
    "    count_vectorizer = CountVectorizer(stop_words='english', token_pattern='[a-z]+', ngram_range=(1, 2))\n",
    "    count_vectorizer.fit(train_data)\n",
    "\n",
    "    print(multinomial_nb(count_vectorizer, train_data, train_labels, test_data, test_labels))\n",
    "    print(logistic_regression(count_vectorizer, train_data, train_labels, test_data, test_labels))\n",
    "    print(svc(count_vectorizer, train_data, train_labels, test_data, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 50)\t1\n",
      "  (0, 407)\t1\n",
      "  (0, 558)\t1\n",
      "  (0, 787)\t1\n",
      "  (0, 1180)\t1\n",
      "  (0, 1448)\t1\n",
      "  (0, 1609)\t1\n",
      "  (0, 2994)\t1\n",
      "  (0, 3112)\t1\n",
      "  (0, 5191)\t1\n",
      "  (0, 5316)\t1\n",
      "  (0, 8164)\t1\n",
      "  (0, 11387)\t1\n",
      "  (0, 11913)\t1\n",
      "  (0, 12048)\t1\n",
      "  (0, 12359)\t1\n",
      "  (0, 13178)\t1\n",
      "  (0, 13858)\t1\n",
      "  (0, 15565)\t1\n",
      "  (0, 16500)\t1\n",
      "  (0, 17177)\t1\n",
      "  (0, 17223)\t1\n",
      "  (0, 18856)\t1\n",
      "  (0, 19378)\t1\n",
      "  (1, 1828)\t1\n",
      "  :\t:\n",
      "  (53068, 15987)\t1\n",
      "  (53068, 16116)\t1\n",
      "  (53068, 16219)\t1\n",
      "  (53068, 16610)\t1\n",
      "  (53068, 17659)\t1\n",
      "  (53068, 17718)\t1\n",
      "  (53068, 18643)\t1\n",
      "  (53068, 18708)\t1\n",
      "  (53068, 19068)\t1\n",
      "  (53068, 19446)\t1\n",
      "  (53069, 216)\t1\n",
      "  (53069, 655)\t1\n",
      "  (53069, 2122)\t1\n",
      "  (53069, 4317)\t1\n",
      "  (53069, 5191)\t1\n",
      "  (53069, 6688)\t1\n",
      "  (53069, 6811)\t1\n",
      "  (53069, 9497)\t1\n",
      "  (53069, 12359)\t1\n",
      "  (53069, 13460)\t1\n",
      "  (53069, 14081)\t1\n",
      "  (53069, 14378)\t1\n",
      "  (53069, 15428)\t1\n",
      "  (53069, 17576)\t1\n",
      "  (53069, 19633)\t1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=['this open with aroma of char earth violet and wild berri the straightforward palat offer black raspberri tart cherri and a hint of anis alongsid polish tannin its rather simpl for a barolo and near access drink 2016–2021'\n 'this bold and fruiti carri scent and of cherri candi its a fine bottl for chill and share with summer picnic food'\n 'a touch green and veget on the nose with hint of can pea and bell pepper fortun there enough lime and miner to keep it fresh feel crisp tight and wet with green note pervad core citrus finish pithi and zesti with mild bitter'\n ...\n 'dilut oddbal aroma of blueberri and currant are render earthi and less than fulli clean by a whiff of compost this feel basic and jammi while floral berri settl on herbal and pepperi it finish lean'\n 'this fabul has been with cab and petit verdot its incred complex in both and structur offer wave of blackberri and cherri currant dark chocol and toast that go on and on into a long spici finish the grape come from various sourc includ st helena and atlas peak show winemak tom hind masteri of the art of'\n 'fruiti and ripe this is a tight very fresh the crispest appl and brightest lemon give a refresh shock to the palat the should probabl age for a few year so drink after 2014'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-54ab6838fc24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-7c144b65a012>\u001b[0m in \u001b[0;36mrun_experiments\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     print(multinomial_nb(count_vectorizer, train_data, train_labels, test_data, test_labels))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_vectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_vectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-e3ea1fa7bdc3>\u001b[0m in \u001b[0;36mlogistic_regression\u001b[0;34m(vectorizer, train_data, train_labels, test_data, test_labels)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-fb3447e2a19f>\u001b[0m in \u001b[0;36mresample\u001b[0;34m(data, labels)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_sample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \"\"\"\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \"\"\"\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_hash_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_hash_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhash_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=['this open with aroma of char earth violet and wild berri the straightforward palat offer black raspberri tart cherri and a hint of anis alongsid polish tannin its rather simpl for a barolo and near access drink 2016–2021'\n 'this bold and fruiti carri scent and of cherri candi its a fine bottl for chill and share with summer picnic food'\n 'a touch green and veget on the nose with hint of can pea and bell pepper fortun there enough lime and miner to keep it fresh feel crisp tight and wet with green note pervad core citrus finish pithi and zesti with mild bitter'\n ...\n 'dilut oddbal aroma of blueberri and currant are render earthi and less than fulli clean by a whiff of compost this feel basic and jammi while floral berri settl on herbal and pepperi it finish lean'\n 'this fabul has been with cab and petit verdot its incred complex in both and structur offer wave of blackberri and cherri currant dark chocol and toast that go on and on into a long spici finish the grape come from various sourc includ st helena and atlas peak show winemak tom hind masteri of the art of'\n 'fruiti and ripe this is a tight very fresh the crispest appl and brightest lemon give a refresh shock to the palat the should probabl age for a few year so drink after 2014'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "run_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
