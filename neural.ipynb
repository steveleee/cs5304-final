{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "USE_CUDA = False\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"data/winemag-data-130k-v2.csv\")\n",
    "raw_descriptions = raw_data['description']\n",
    "raw_varieties = raw_data['variety']\n",
    "raw_provinces = raw_data['province']\n",
    "raw_points = raw_data['points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sauvignon blanc': 0, 'rosé': 1, 'red blend': 2, 'cabernet sauvignon': 3, 'bordeaux-style red blend': 4, 'merlot': 5, 'chardonnay': 6, 'pinot noir': 7, 'syrah': 8, 'riesling': 9}\n"
     ]
    }
   ],
   "source": [
    "valid_varieties = set(['pinot noir', 'chardonnay', 'cabernet sauvignon', 'red blend', 'bordeaux-style red blend', 'riesling', 'sauvignon blanc', 'syrah', 'rosé', 'merlot']) #, 'nebbiolo', 'zinfandel', 'sangiovese', 'malbec', 'portuguese red', 'white blend', 'sparkling blend', 'tempranillo', 'rhône-style red blend', 'pinot gris', 'champagne blend', 'cabernet franc', 'grüner veltliner', 'portuguese white', 'bordeaux-style white blend', 'pinot grigio', 'gamay', 'gewürztraminer', 'viognier', 'shiraz'])\n",
    "excluded_words = set(['pinot', 'noir', 'chardonnay', 'cabernet', 'sauvignon', 'bordeaux-style', 'blend', 'riesling', 'sauvignon',  'blanc', 'syrah', 'rosé', 'merlot', 'nebbiolo', 'zinfandel', 'sangiovese', 'malbec', 'portuguese', 'tempranillo', 'rhône-style', 'pinot', 'gris', 'champagne', 'franc', 'grüner',  'veltliner', 'portuguese', 'grigio', 'gamay', 'gewürztraminer', 'viognier', 'shiraz', 'flavor', 'wine'])\n",
    "\n",
    "label_to_idx = {word: idx for idx, word in enumerate(valid_varieties)}\n",
    "print(label_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71322 71322\n"
     ]
    }
   ],
   "source": [
    "# Extract rows with just the valid varieties\n",
    "\n",
    "def process_description(des):\n",
    "    processed_description = []\n",
    "    \n",
    "    table = str.maketrans({key: None for key in string.punctuation})\n",
    "    des = des.translate(table)\n",
    "    \n",
    "    for word in des.split():\n",
    "        word = word.lower()\n",
    "        if word not in excluded_words:\n",
    "            processed_description.append(word)\n",
    "            \n",
    "    return \" \".join(processed_description)\n",
    "\n",
    "data, labels = [], []\n",
    "\n",
    "for i, variety in enumerate(raw_varieties):\n",
    "    if type(variety) is not float:\n",
    "        variety = variety.lower()\n",
    "        if variety in valid_varieties:\n",
    "            if type(raw_descriptions[i]) is not float:                \n",
    "                data.append(process_description(raw_descriptions[i]))\n",
    "                labels.append(label_to_idx[variety])\n",
    "\n",
    "print(len(data), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pineapple rind lemon pith and orange blossom start off the aromas the palate is a bit more opulent with notes of honeydrizzled guava and mango giving way to a slightly astringent semidry finish', 'much like the regular bottling from 2012 this comes across as rather rough and tannic with rustic earthy herbal characteristics nonetheless if you think of it as a pleasantly unfussy country its a good companion to a hearty winter stew', 'soft supple plum envelopes an oaky structure in this supported by 15 coffee and chocolate complete the picture finishing strong at the end resulting in a valuepriced of attractive and immediate accessibility', 'slightly reduced this offers a chalky tannic backbone to an otherwise juicy explosion of rich black cherry the whole accented throughout by firm oak and cigar box', 'building on 150 years and six generations of winemaking tradition the winery trends toward a leaner style with the classic california buttercream aroma cut by tart green apple in this good everyday sipping flavors that range from pear to barely ripe pineapple prove approachable but not distinctive']\n"
     ]
    }
   ],
   "source": [
    "# Print a sample of the data\n",
    "\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57057,) (57057,)\n",
      "(14265,) (14265,)\n"
     ]
    }
   ],
   "source": [
    "# Split 80/20 training-test\n",
    "\n",
    "stacked = np.hstack([np.array(data).reshape(-1, 1), np.array(labels).reshape(-1, 1)])\n",
    "np.random.shuffle(stacked)\n",
    "\n",
    "train_split = int(len(stacked) * 0.8)\n",
    "\n",
    "train_data = stacked[:train_split, :1].reshape(-1,)\n",
    "train_labels = np.array(stacked[:train_split, 1:].reshape(-1,), dtype=np.int32)\n",
    "\n",
    "test_data = stacked[train_split:, :1].reshape(-1,)\n",
    "test_labels = np.array(stacked[train_split:, 1:].reshape(-1,), dtype= np.int32)\n",
    "\n",
    "print(train_data.shape, train_labels.shape)\n",
    "print(test_data.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = 'data/glove/glove.6B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove(path):\n",
    "    \"\"\"\n",
    "    creates a dictionary mapping words to vectors from a file in glove format.\n",
    "    \"\"\"\n",
    "    with open(path) as f:\n",
    "        glove = {}\n",
    "        for line in f.readlines():\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.array(values[1:], dtype='float32')\n",
    "            glove[word] = vector\n",
    "        return glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(path, word2idx, embedding_dim=50):\n",
    "    with open(path) as f:\n",
    "        embeddings = np.zeros((len(word2idx), embedding_dim))\n",
    "        for line in f.readlines():\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            index = word2idx.get(word)\n",
    "            if index:\n",
    "                vector = np.array(values[1:], dtype='float32')\n",
    "                embeddings[index] = vector\n",
    "        return torch.from_numpy(embeddings).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.6 s, sys: 880 ms, total: 25.5 s\n",
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%time glove = load_glove(glove_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', token_pattern='[a-z]+', ngram_range=(1, 1))\n",
    "count_vectorizer.fit(train_data)\n",
    "vocab = count_vectorizer.vocabulary_.keys()\n",
    "word2idx = {word: idx for idx, word in enumerate(vocab)} # create word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_sequence(data):\n",
    "    max_len = 0\n",
    "    \n",
    "    for seq in data:\n",
    "        if len(seq) > max_len:\n",
    "            max_len = len(seq)\n",
    "    \n",
    "    return max_len\n",
    "\n",
    "def pad_with_max_length(max_len, data):\n",
    "    res = np.zeros((len(data), max_len))\n",
    "    for i, row in enumerate(data):\n",
    "        for j, num in enumerate(row):\n",
    "            res[i, j] = num\n",
    "    return np.array(res, dtype=np.int64)\n",
    "\n",
    "def convert_to_embedding_vocab(data):\n",
    "    res = []\n",
    "    for des in data:\n",
    "        converted = []\n",
    "        for word in des.split(\" \"):\n",
    "            if word in word2idx:\n",
    "                converted.append(word2idx[word])\n",
    "        res.append(np.array(converted, dtype=np.int64))\n",
    "        \n",
    "    res = np.array(res)\n",
    "    \n",
    "    max_len = longest_sequence(res)\n",
    "    \n",
    "    return pad_with_max_length(max_len, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = convert_to_embedding_vocab(train_data)\n",
    "train_data = torch.from_numpy(train_data)\n",
    "train_labels = torch.from_numpy(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = convert_to_embedding_vocab(test_data)\n",
    "test_data = torch.from_numpy(test_data)\n",
    "test_labels = torch.from_numpy(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.utils.data.TensorDataset(train_data, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=50, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embeddings = load_glove_embeddings(glove_path, word2idx, embedding_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, embeddings, num_outputs, kernel_num, kernel_sizes, static):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.static = static\n",
    "        \n",
    "        V = embeddings.shape[0]\n",
    "        D = embeddings.shape[1]\n",
    "        C = num_outputs\n",
    "        Ci = 1\n",
    "        Co = kernel_num\n",
    "        Ks = kernel_sizes\n",
    "\n",
    "        self.embed = nn.Embedding(V, D)\n",
    "#         self.embed.weight = nn.Parameter(embeddings)\n",
    "        # self.convs1 = [nn.Conv2d(Ci, Co, (K, D)) for K in Ks]\n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(Ci, Co, (K, D)) for K in Ks])\n",
    "        '''\n",
    "        self.conv13 = nn.Conv2d(Ci, Co, (3, D))\n",
    "        self.conv14 = nn.Conv2d(Ci, Co, (4, D))\n",
    "        self.conv15 = nn.Conv2d(Ci, Co, (5, D))\n",
    "        '''\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(len(Ks)*Co, C)\n",
    "\n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = F.relu(conv(x)).squeeze(3)  # (N, Co, W)\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)  # (N, W, D)\n",
    "        \n",
    "        if self.static:\n",
    "            x = Variable(x)\n",
    "\n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
    "\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
    "\n",
    "        x = torch.cat(x, 1)\n",
    "\n",
    "        '''\n",
    "        x1 = self.conv_and_pool(x,self.conv13) #(N,Co)\n",
    "        x2 = self.conv_and_pool(x,self.conv14) #(N,Co)\n",
    "        x3 = self.conv_and_pool(x,self.conv15) #(N,Co)\n",
    "        x = torch.cat((x1, x2, x3), 1) # (N,len(Ks)*Co)\n",
    "        '''\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        logit = self.fc1(x)  # (N, C)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, testloader, optimizer, epochs=10, scheduler=None):\n",
    "    print(\"Start training\")\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        print(\"Start epoch: \" + str(epoch + 1))\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        total_batches = 0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            # wrap them in Variable\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            \n",
    "            if USE_CUDA:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.data[0]\n",
    "            total_batches += 1\n",
    "\n",
    "        print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 100))\n",
    "\n",
    "        val_loss = validate(model, testloader)\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for data in testloader:\n",
    "        descriptions, labels = data\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            descriptions, labels = descriptions.cuda(), labels.cuda()\n",
    "            \n",
    "        outputs = model(Variable(descriptions))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    print('Accuracy: %f%%' % (\n",
    "        100 * float(correct) / total))\n",
    "    \n",
    "    return float(correct) / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Start epoch: 1\n",
      "[1,  1142] loss: 20.702\n",
      "Accuracy: 55.646688%\n",
      "Start epoch: 2\n",
      "[2,  1142] loss: 12.351\n",
      "Accuracy: 53.753943%\n",
      "Start epoch: 3\n",
      "[3,  1142] loss: 9.693\n",
      "Accuracy: 59.298984%\n",
      "Start epoch: 4\n",
      "[4,  1142] loss: 8.988\n",
      "Accuracy: 54.293726%\n",
      "Start epoch: 5\n",
      "[5,  1142] loss: 11.395\n",
      "Accuracy: 46.147914%\n",
      "Start epoch: 6\n",
      "[6,  1142] loss: 14.318\n",
      "Accuracy: 56.459867%\n",
      "Start epoch: 7\n",
      "[7,  1142] loss: 16.294\n",
      "Accuracy: 59.880827%\n",
      "Start epoch: 8\n",
      "[8,  1142] loss: 19.933\n",
      "Accuracy: 59.011567%\n",
      "Start epoch: 9\n",
      "[9,  1142] loss: 22.409\n",
      "Accuracy: 62.467578%\n",
      "Start epoch: 10\n",
      "[10,  1142] loss: 22.400\n",
      "Accuracy: 60.708027%\n",
      "Start epoch: 11\n",
      "[11,  1142] loss: 23.710\n",
      "Accuracy: 57.539432%\n",
      "Start epoch: 12\n",
      "[12,  1142] loss: 25.128\n",
      "Accuracy: 60.161234%\n",
      "Start epoch: 13\n",
      "[13,  1142] loss: 26.242\n",
      "Accuracy: 59.284963%\n",
      "Start epoch: 14\n",
      "[14,  1142] loss: 24.744\n",
      "Accuracy: 61.738521%\n",
      "Start epoch: 15\n",
      "[15,  1142] loss: 21.975\n",
      "Accuracy: 62.509639%\n",
      "Start epoch: 16\n",
      "[16,  1142] loss: 20.392\n",
      "Accuracy: 63.841570%\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Start epoch: 17\n",
      "[17,  1142] loss: 7.112\n",
      "Accuracy: 65.376796%\n",
      "Start epoch: 18\n",
      "[18,  1142] loss: 1.223\n",
      "Accuracy: 64.963197%\n",
      "Start epoch: 19\n",
      "[19,  1142] loss: 0.282\n",
      "Accuracy: 65.334735%\n",
      "Start epoch: 20\n",
      "[20,  1142] loss: 0.099\n",
      "Accuracy: 65.404837%\n",
      "Start epoch: 21\n",
      "[21,  1142] loss: 0.039\n",
      "Accuracy: 65.390817%\n",
      "Start epoch: 22\n",
      "[22,  1142] loss: 0.027\n",
      "Accuracy: 65.411847%\n",
      "Start epoch: 23\n",
      "[23,  1142] loss: 0.020\n",
      "Accuracy: 65.390817%\n",
      "Start epoch: 24\n",
      "[24,  1142] loss: 0.023\n",
      "Accuracy: 65.376796%\n",
      "Start epoch: 25\n",
      "[25,  1142] loss: 0.028\n",
      "Accuracy: 65.362776%\n",
      "Start epoch: 26\n",
      "[26,  1142] loss: 0.019\n",
      "Accuracy: 65.306695%\n",
      "Start epoch: 27\n",
      "[27,  1142] loss: 0.023\n",
      "Accuracy: 65.397827%\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Start epoch: 28\n",
      "[28,  1142] loss: 0.018\n",
      "Accuracy: 65.390817%\n",
      "Start epoch: 29\n",
      "[29,  1142] loss: 0.015\n",
      "Accuracy: 65.369786%\n",
      "Start epoch: 30\n",
      "[30,  1142] loss: 0.013\n",
      "Accuracy: 65.334735%\n",
      "Start epoch: 31\n",
      "[31,  1142] loss: 0.011\n",
      "Accuracy: 65.327725%\n",
      "Start epoch: 32\n",
      "[32,  1142] loss: 0.008\n",
      "Accuracy: 65.341746%\n",
      "Start epoch: 33\n",
      "[33,  1142] loss: 0.006\n",
      "Accuracy: 65.341746%\n",
      "Start epoch: 34\n",
      "[34,  1142] loss: 0.005\n",
      "Accuracy: 65.334735%\n",
      "Start epoch: 35\n",
      "[35,  1142] loss: 0.004\n",
      "Accuracy: 65.327725%\n",
      "Start epoch: 36\n",
      "[36,  1142] loss: 0.004\n",
      "Accuracy: 65.355766%\n",
      "Start epoch: 37\n",
      "[37,  1142] loss: 0.004\n",
      "Accuracy: 65.348756%\n",
      "Start epoch: 38\n",
      "[38,  1142] loss: 0.004\n",
      "Accuracy: 65.334735%\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Start epoch: 39\n",
      "[39,  1142] loss: 0.003\n",
      "Accuracy: 65.341746%\n",
      "Start epoch: 40\n",
      "[40,  1142] loss: 0.003\n",
      "Accuracy: 65.341746%\n",
      "Start epoch: 41\n",
      "[41,  1142] loss: 0.003\n",
      "Accuracy: 65.341746%\n",
      "Start epoch: 42\n",
      "[42,  1142] loss: 0.003\n",
      "Accuracy: 65.334735%\n",
      "Start epoch: 43\n",
      "[43,  1142] loss: 0.003\n",
      "Accuracy: 65.334735%\n",
      "Start epoch: 44\n",
      "[44,  1142] loss: 0.003\n",
      "Accuracy: 65.341746%\n",
      "Start epoch: 45\n",
      "[45,  1142] loss: 0.003\n",
      "Accuracy: 65.348756%\n",
      "Start epoch: 46\n",
      "[46,  1142] loss: 0.003\n",
      "Accuracy: 65.348756%\n",
      "Start epoch: 47\n",
      "[47,  1142] loss: 0.003\n",
      "Accuracy: 65.348756%\n",
      "Start epoch: 48\n",
      "[48,  1142] loss: 0.003\n",
      "Accuracy: 65.348756%\n",
      "Start epoch: 49\n",
      "[49,  1142] loss: 0.003\n",
      "Accuracy: 65.348756%\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Start epoch: 50\n",
      "[50,  1142] loss: 0.003\n",
      "Accuracy: 65.348756%\n",
      "Start epoch: 51\n",
      "[51,  1142] loss: 0.003\n",
      "Accuracy: 65.348756%\n",
      "Start epoch: 52\n",
      "[52,  1142] loss: 0.003\n",
      "Accuracy: 65.348756%\n",
      "Start epoch: 53\n",
      "[53,  1142] loss: 0.003\n",
      "Accuracy: 65.348756%\n",
      "Start epoch: 54\n",
      "[54,  1142] loss: 0.003\n",
      "Accuracy: 65.348756%\n",
      "Start epoch: 55\n",
      "[55,  1142] loss: 0.003\n",
      "Accuracy: 65.348756%\n",
      "Start epoch: 56\n",
      "[56,  1142] loss: 0.003\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-2ce971b658d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-d66cd3dae784>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, testloader, optimizer, epochs, scheduler)\u001b[0m\n\u001b[1;32m     34\u001b[0m                       (epoch + 1, i + 1, running_loss / 100))\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-f1621037c652>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, testloader)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mdescriptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = CNN(embeddings=glove_embeddings, num_outputs=len(label_to_idx), kernel_num=100, kernel_sizes=[3,4,5], static=False)\n",
    "\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, mode='min', verbose=True)\n",
    "\n",
    "train(model, trainloader, testloader, optimizer=optimizer, scheduler=scheduler, epochs=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.348756%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6534875569575885"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, embeddings, hidden_dim, label_size):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embeddings = nn.Embedding(embeddings.shape[0], embeddings.shape[1])\n",
    "        self.lstm = nn.LSTM(embeddings.shape[1], hidden_dim)\n",
    "        self.hidden2label = nn.Linear(hidden_dim, label_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # the first is the hidden h\n",
    "        # the second is the cell  c\n",
    "        return (torch.autograd.Variable(torch.zeros(1, 1, self.hidden_dim)),\n",
    "                torch.autograd.Variable(torch.zeros(1, 1, self.hidden_dim)))\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        x = embeds.view(len(sentence), 1, -1)\n",
    "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
    "        y  = self.hidden2label(lstm_out[-1])\n",
    "        log_probs = F.log_softmax(y)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = LSTMClassifier(glove_embeddings, 100, 20)\n",
    "\n",
    "if USE_CUDA:\n",
    "    lstm_model = lstm_model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(lstm_model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# train(model, trainloader, testloader, optimizer=optimizer, scheduler=None, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
